{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T18:14:47.864812Z",
     "start_time": "2025-06-20T18:14:16.896284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "local_path = kagglehub.dataset_download(\"erlichsefi/israeli-supermarkets-2024\")\n",
    "\n",
    "selected_supermarkets = [\n",
    "    \"shufersal\", \"rami_levy\", \"victory\", \"tiv_taam\", \"yohananof\", \"osher_ad\", \"mega\"\n",
    "]\n",
    "\n",
    "save_dir='data'\n",
    "product_dfs = []\n",
    "for market in selected_supermarkets:\n",
    "    filename = f\"price_file_{market}.csv\"\n",
    "    file_path = os.path.join(local_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df[\"supermarket\"] = market\n",
    "        product_dfs.append(df)\n",
    "\n",
    "        df.to_csv(os.path.join(save_dir, filename), index=False)\n",
    "        print(f\"âœ… Loaded & Saved: {filename} ({len(df)} rows)\")\n",
    "    else:\n",
    "        print(f\"âŒ Missing: {filename}\")\n",
    "\n",
    "\n",
    "if product_dfs:\n",
    "    all_products = pd.concat(product_dfs, ignore_index=True)\n",
    "    combined_path = os.path.join(save_dir, \"combined_supermarket_products.csv\")\n",
    "    all_products.to_csv(combined_path, index=False)\n",
    "    print(f\"\\nğŸ“¦ Total products: {len(all_products)}\")\n",
    "    print(f\"âœ… Combined data saved to: {combined_path}\")\n",
    "    print(all_products.head())\n",
    "else:\n",
    "    print(\"âŒ No product data loaded.\")\n"
   ],
   "id": "214d70f1b2cd8600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded & Saved: price_file_shufersal.csv (854248 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nagham Omar\\AppData\\Local\\Temp\\ipykernel_30360\\1759887513.py:17: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded & Saved: price_file_rami_levy.csv (346443 rows)\n",
      "âœ… Loaded & Saved: price_file_victory.csv (4043 rows)\n",
      "âœ… Loaded & Saved: price_file_tiv_taam.csv (6682 rows)\n",
      "âœ… Loaded & Saved: price_file_yohananof.csv (24514 rows)\n",
      "âœ… Loaded & Saved: price_file_osher_ad.csv (3792 rows)\n",
      "âœ… Loaded & Saved: price_file_mega.csv (155509 rows)\n",
      "\n",
      "ğŸ“¦ Total products: 1395231\n",
      "âœ… Combined data saved to: data\\combined_supermarket_products.csv\n",
      "               found_folder                                file_name  \\\n",
      "0  app_data/dumps/Shufersal  Price7290027600007-131-202506180200.xml   \n",
      "1                       NaN                                      NaN   \n",
      "2                       NaN                                      NaN   \n",
      "3                       NaN                                      NaN   \n",
      "4                       NaN                                      NaN   \n",
      "\n",
      "        chainid  subchainid  storeid  bikoretno   priceupdatedate  \\\n",
      "0  7.290028e+12         7.0    131.0        9.0  2025-06-17 05:30   \n",
      "1           NaN         NaN      NaN        NaN               NaN   \n",
      "2           NaN         NaN      NaN        NaN               NaN   \n",
      "3           NaN         NaN      NaN        NaN               NaN   \n",
      "4           NaN         NaN      NaN        NaN               NaN   \n",
      "\n",
      "       itemcode  itemtype                  itemname  ... allowdiscount  \\\n",
      "0  1.600019e+10       1.0   ×“×’× ×™ ×¤×™×™×‘×¨ ×•×•××Ÿ 555 ×’×¨×  ...           1.0   \n",
      "1  2.172334e+10       NaN         ×¨×•×˜×‘ ×“×’×™× 300 ×\"×œ  ...           NaN   \n",
      "2  3.046920e+12       NaN  ×©×•×§.××™×œ×“ 85% ××§×¡×œ× ×¡100×’×¨  ...           NaN   \n",
      "3  4.000417e+12       NaN  ×©×•×§×•×œ×“ ××¨×™×¨ ×¢× ××¨×¦×™×¤×Ÿ100  ...           NaN   \n",
      "4  4.033100e+12       NaN          ×›×××œ ×¦×”×•×‘ ×˜×‘×§ ×—×¤  ...           0.0   \n",
      "\n",
      "  itemstatus supermarket itemnm  itemid  manufacturename  \\\n",
      "0        1.0   shufersal    NaN     NaN              NaN   \n",
      "1        NaN   shufersal    NaN     NaN              NaN   \n",
      "2        NaN   shufersal    NaN     NaN              NaN   \n",
      "3        NaN   shufersal    NaN     NaN              NaN   \n",
      "4        0.0   shufersal    NaN     NaN              NaN   \n",
      "\n",
      "  manufactureitemdescription unitmeasure  lastupdatedate  lastupdatetime  \n",
      "0                        NaN         NaN             NaN             NaN  \n",
      "1                        NaN         NaN             NaN             NaN  \n",
      "2                        NaN         NaN             NaN             NaN  \n",
      "3                        NaN         NaN             NaN             NaN  \n",
      "4                        NaN         NaN             NaN             NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:09:28.494868Z",
     "start_time": "2025-06-20T20:06:35.742286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "data_path = kagglehub.dataset_download(\"erlichsefi/israeli-supermarkets-2024\")\n",
    "\n",
    "supermarkets = [\n",
    "    \"shufersal\", \"rami_levy\", \"victory\", \"tiv_taam\", \"yohananof\", \"osher_ad\", \"mega\"\n",
    "]\n",
    "\n",
    "product_dfs = []\n",
    "promo_dfs = []\n",
    "\n",
    "for market in supermarkets:\n",
    "    prod_file = f\"price_full_file_{market}.csv\"\n",
    "    promo_file = f\"promo_full_file_{market}.csv\"\n",
    "    prod_path = os.path.join(data_path, prod_file)\n",
    "    promo_path = os.path.join(data_path, promo_file)\n",
    "\n",
    "    if os.path.exists(prod_path):\n",
    "        df_prod = pd.read_csv(prod_path, low_memory=False)\n",
    "        df_prod[\"supermarket\"] = market\n",
    "        product_dfs.append(df_prod)\n",
    "        print(f\"âœ… Loaded product file for {market}\")\n",
    "    else:\n",
    "        print(f\"âŒ Product file not found for {market}\")\n",
    "\n",
    "    if os.path.exists(promo_path):\n",
    "        df_promo = pd.read_csv(promo_path, low_memory=False)\n",
    "        df_promo[\"supermarket\"] = market\n",
    "        promo_dfs.append(df_promo)\n",
    "        print(f\"âœ… Loaded promo file for {market}\")\n",
    "    else:\n",
    "        print(f\"âŒ Promo file not found for {market}\")\n",
    "\n",
    "if not product_dfs:\n",
    "    raise ValueError(\"No product data loaded.\")\n",
    "\n",
    "all_products = pd.concat(product_dfs, ignore_index=True)\n",
    "\n",
    "if promo_dfs:\n",
    "    all_promos = pd.concat(promo_dfs, ignore_index=True)\n",
    "else:\n",
    "    all_promos = pd.DataFrame()\n",
    "\n",
    "# Ensure 'priceupdatedate' is parsed\n",
    "if 'priceupdatedate' in all_products.columns:\n",
    "    all_products['priceupdatedate'] = pd.to_datetime(all_products['priceupdatedate'], errors='coerce')\n",
    "    # Keep only the most recent for each (itemcode, supermarket)\n",
    "    all_products = all_products.sort_values('priceupdatedate', ascending=False)\n",
    "    products_latest = all_products.drop_duplicates(subset=['itemcode', 'supermarket'], keep='first')\n",
    "else:\n",
    "    products_latest = all_products.drop_duplicates(subset=['itemcode', 'supermarket'], keep='first')\n",
    "\n",
    "# Merge promo info (add promo columns to product info, do not drop other product columns)\n",
    "if not all_promos.empty and 'itemcode' in all_promos.columns:\n",
    "    # Use most recent promo if date exists\n",
    "    if 'priceupdatedate' in all_promos.columns:\n",
    "        all_promos['priceupdatedate'] = pd.to_datetime(all_promos['priceupdatedate'], errors='coerce')\n",
    "        all_promos = all_promos.sort_values('priceupdatedate', ascending=False)\n",
    "        promos_latest = all_promos.drop_duplicates(subset=['itemcode', 'supermarket'], keep='first')\n",
    "    else:\n",
    "        promos_latest = all_promos\n",
    "    # Only merge on shared columns + keep all product columns\n",
    "    merge_cols = ['itemcode', 'supermarket']\n",
    "    promo_cols = [c for c in promos_latest.columns if c not in merge_cols]\n",
    "    df_final = products_latest.merge(\n",
    "        promos_latest[merge_cols + promo_cols],\n",
    "        on=merge_cols,\n",
    "        how='left',\n",
    "        suffixes=('', '_promo')\n",
    "    )\n",
    "else:\n",
    "    df_final = products_latest\n",
    "\n",
    "# Save with all original and promo columns\n",
    "df_final.to_csv(\"data/unique_products_with_latest_price_and_promo_FULL.csv\", index=False)\n",
    "print(\"âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\")\n",
    "print(df_final.head())\n"
   ],
   "id": "6939e6f586629029",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded product file for shufersal\n",
      "âœ… Loaded promo file for shufersal\n",
      "âœ… Loaded product file for rami_levy\n",
      "âœ… Loaded promo file for rami_levy\n",
      "âœ… Loaded product file for victory\n",
      "âœ… Loaded promo file for victory\n",
      "âœ… Loaded product file for tiv_taam\n",
      "âœ… Loaded promo file for tiv_taam\n",
      "âœ… Loaded product file for yohananof\n",
      "âœ… Loaded promo file for yohananof\n",
      "âœ… Loaded product file for osher_ad\n",
      "âœ… Loaded promo file for osher_ad\n",
      "âœ… Loaded product file for mega\n",
      "âœ… Loaded promo file for mega\n",
      "âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\n",
      "  found_folder file_name  chainid  subchainid  storeid  bikoretno  \\\n",
      "0          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "1          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "2          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "3          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "4          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "\n",
      "      priceupdatedate      itemcode  itemtype                    itemname  \\\n",
      "0 2025-06-18 22:32:00  7.290107e+12       NaN        ×‘×¤×œ×•×ª ×˜×•×¨×˜×™×ª 360 ×’×¨×   \n",
      "1 2025-06-18 22:32:00  7.290003e+12       NaN    ×—×××” ×¦×¨×¤×ª×™×ª ×¤×œ××©×¨×“ ×‘××©×§×œ   \n",
      "2 2025-06-18 22:32:00  7.290018e+12       NaN  ×¡×•×›×¨×–×™×ª ×¡×•×›×¨×œ×•×– 200 ×˜×‘×œ×™×•×ª   \n",
      "3 2025-06-18 22:32:00  7.290001e+12       NaN    ×¡×•×›×¨×–×™×ª ×§× ×§×Ÿ 1200 ×˜×‘×œ×™×•×ª   \n",
      "4 2025-06-18 22:32:00  7.290019e+12       NaN      ×§××— ×©×§×“×™× ×›×¨× - 250 ×’×¨   \n",
      "\n",
      "   ... itemtype_promo isgiftitem clubid minpurchaseamount  \\\n",
      "0  ...            NaN        NaN    NaN               NaN   \n",
      "1  ...            NaN        NaN    NaN               NaN   \n",
      "2  ...            NaN        NaN    NaN               NaN   \n",
      "3  ...            NaN        NaN    NaN               NaN   \n",
      "4  ...            NaN        NaN    NaN               NaN   \n",
      "\n",
      "   minnoofitemsoffered  additionalscoupon additionalsgiftcount  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN                  NaN   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN                  NaN   \n",
      "\n",
      "  additionalstotals  additionalsminbasketamount  maxamount  \n",
      "0               NaN                         NaN        NaN  \n",
      "1               NaN                         NaN        NaN  \n",
      "2               NaN                         NaN        NaN  \n",
      "3               NaN                         NaN        NaN  \n",
      "4               NaN                         NaN        NaN  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:17:35.732884Z",
     "start_time": "2025-06-20T20:17:35.705436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXCLUDE_KEYWORDS = [\n",
    "    \"×©××¤×•\", \"×©××¤×•×•\", \"×¡×‘×•×Ÿ\", \"××¨×›×š\", \"××©×—×ª ×©×™× ×™×™×\", \"××‘×¨×©×ª ×©×™× ×™×™×\", \"× ×™×™×¨ ×˜×•××œ×˜\", \"×—×•××¨ × ×™×§×•×™\",\n",
    "    \"×˜×™×˜×•×œ×™×\", \"×¤×“×™×\", \"×ª×—×‘×•×©×ª\", \"××‘×§×ª ×›×‘×™×¡×”\", \"××¨×›×š ×›×‘×™×¡×”\", \"×›×œ×™× ×—×“ ×¤×¢××™×™×\",\n",
    "    \"×©×§×™×•×ª ××©×¤×”\", \"×©×§×™×ª ××©×¤×”\", \"× ×•×–×œ ×¨×¦×¤×”\", \"×—×•××¨×™ × ×™×§×•×™\",\n",
    "    # Add more as needed\n",
    "    \"shampoo\", \"soap\", \"detergent\", \"toothpaste\", \"toothbrush\", \"diaper\", \"pad\", \"sanitary\",\n",
    "    \"cleaner\", \"dish\", \"garbage bag\", \"floor cleaner\", \"laundry\", \"disposable\"\n",
    "]\n"
   ],
   "id": "2df864f086b17e2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:18:22.108798Z",
     "start_time": "2025-06-20T20:18:15.146087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def contains_exclude(text):\n",
    "    text = str(text).lower()\n",
    "    for kw in EXCLUDE_KEYWORDS:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the filter on 'itemname' and optionally 'manufactureitemdescription'\n",
    "before = len(df_final)\n",
    "df_final = df_final[~(\n",
    "    df_final['itemname'].apply(contains_exclude) |\n",
    "    (df_final['manufactureitemdescription'].apply(contains_exclude) if 'manufactureitemdescription' in df_final.columns else False)\n",
    ")]\n",
    "after = len(df_final)\n",
    "print(f\"âœ… Filtered out {before-after} non-food/non-cooking products. Remaining: {after}\")\n",
    "df_final.to_csv(\"data/unique_products_with_latest_price_and_promo_FULL.csv\", index=False)\n",
    "print(\"âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\")\n",
    "print(df_final.head())"
   ],
   "id": "7b2bd52d77b50b7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtered out 0 non-food/non-cooking products. Remaining: 143736\n",
      "âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\n",
      "  found_folder file_name  chainid  subchainid  storeid  bikoretno  \\\n",
      "0          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "1          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "2          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "3          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "4          NaN       NaN      NaN         NaN      NaN        NaN   \n",
      "\n",
      "      priceupdatedate      itemcode  itemtype                    itemname  \\\n",
      "0 2025-06-18 22:32:00  7.290107e+12       NaN        ×‘×¤×œ×•×ª ×˜×•×¨×˜×™×ª 360 ×’×¨×   \n",
      "1 2025-06-18 22:32:00  7.290003e+12       NaN    ×—×××” ×¦×¨×¤×ª×™×ª ×¤×œ××©×¨×“ ×‘××©×§×œ   \n",
      "2 2025-06-18 22:32:00  7.290018e+12       NaN  ×¡×•×›×¨×–×™×ª ×¡×•×›×¨×œ×•×– 200 ×˜×‘×œ×™×•×ª   \n",
      "3 2025-06-18 22:32:00  7.290001e+12       NaN    ×¡×•×›×¨×–×™×ª ×§× ×§×Ÿ 1200 ×˜×‘×œ×™×•×ª   \n",
      "4 2025-06-18 22:32:00  7.290019e+12       NaN      ×§××— ×©×§×“×™× ×›×¨× - 250 ×’×¨   \n",
      "\n",
      "   ... itemtype_promo isgiftitem clubid minpurchaseamount  \\\n",
      "0  ...            NaN        NaN    NaN               NaN   \n",
      "1  ...            NaN        NaN    NaN               NaN   \n",
      "2  ...            NaN        NaN    NaN               NaN   \n",
      "3  ...            NaN        NaN    NaN               NaN   \n",
      "4  ...            NaN        NaN    NaN               NaN   \n",
      "\n",
      "   minnoofitemsoffered  additionalscoupon additionalsgiftcount  \\\n",
      "0                  NaN                NaN                  NaN   \n",
      "1                  NaN                NaN                  NaN   \n",
      "2                  NaN                NaN                  NaN   \n",
      "3                  NaN                NaN                  NaN   \n",
      "4                  NaN                NaN                  NaN   \n",
      "\n",
      "  additionalstotals  additionalsminbasketamount  maxamount  \n",
      "0               NaN                         NaN        NaN  \n",
      "1               NaN                         NaN        NaN  \n",
      "2               NaN                         NaN        NaN  \n",
      "3               NaN                         NaN        NaN  \n",
      "4               NaN                         NaN        NaN  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:23:21.228777Z",
     "start_time": "2025-06-20T20:23:19.737405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "COLUMNS_TO_KEEP = [\n",
    "    'itemcode', 'itemname', 'manufacturername', 'manufacturecountry',\n",
    "    'manufactureitemdescription', 'unitqty', 'unitofmeasure', 'qtyinpackage',\n",
    "    'itemprice', 'supermarket', 'itemstatus',\n",
    "    'promotiondescription', 'discountedprice', 'promotionstartdate', 'promotionenddate'\n",
    "]\n",
    "df_final = df_final[[c for c in COLUMNS_TO_KEEP if c in df_final.columns]]\n"
   ],
   "id": "691fac764df0276b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:23:23.235368Z",
     "start_time": "2025-06-20T20:23:21.591384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_final.to_csv(\"data/unique_products_with_latest_price_and_promo_FULL.csv\", index=False)\n",
    "print(\"âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\")\n",
    "print(df_final.head())"
   ],
   "id": "99a2045842194cf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: data/unique_products_with_latest_price_and_promo_FULL.csv\n",
      "       itemcode                    itemname manufacturername  \\\n",
      "0  7.290107e+12        ×‘×¤×œ×•×ª ×˜×•×¨×˜×™×ª 360 ×’×¨×              NaN   \n",
      "1  7.290003e+12    ×—×××” ×¦×¨×¤×ª×™×ª ×¤×œ××©×¨×“ ×‘××©×§×œ              NaN   \n",
      "2  7.290018e+12  ×¡×•×›×¨×–×™×ª ×¡×•×›×¨×œ×•×– 200 ×˜×‘×œ×™×•×ª              NaN   \n",
      "3  7.290001e+12    ×¡×•×›×¨×–×™×ª ×§× ×§×Ÿ 1200 ×˜×‘×œ×™×•×ª              NaN   \n",
      "4  7.290019e+12      ×§××— ×©×§×“×™× ×›×¨× - 250 ×’×¨              NaN   \n",
      "\n",
      "  manufacturecountry  manufactureitemdescription  unitqty unitofmeasure  \\\n",
      "0                NaN                         NaN      NaN           NaN   \n",
      "1               ×¦×¨×¤×ª                         NaN      NaN           NaN   \n",
      "2                NaN                         NaN  Unknown       Unknown   \n",
      "3            ×œ× ×™×“×•×¢                         NaN      NaN           NaN   \n",
      "4                ×¤×¨×•                         NaN      NaN           NaN   \n",
      "\n",
      "  qtyinpackage  itemprice supermarket  itemstatus promotiondescription  \\\n",
      "0          NaN       23.9    tiv_taam         NaN                  NaN   \n",
      "1          NaN       75.0    tiv_taam         NaN                  NaN   \n",
      "2          NaN       26.9    tiv_taam         NaN                  NaN   \n",
      "3          NaN       30.9    tiv_taam         NaN                  NaN   \n",
      "4          NaN       21.9    tiv_taam         NaN                  NaN   \n",
      "\n",
      "   discountedprice promotionstartdate promotionenddate  \n",
      "0              NaN                NaN              NaN  \n",
      "1              NaN                NaN              NaN  \n",
      "2              NaN                NaN              NaN  \n",
      "3              NaN                NaN              NaN  \n",
      "4              NaN                NaN              NaN  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T17:25:55.534610Z",
     "start_time": "2025-06-23T17:25:07.141929Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install google-cloud-translate pandas\n",
   "id": "96d4e37ace3dd7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-translate\n",
      "  Downloading google_cloud_translate-3.20.3-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-cloud-translate)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=1.4.4 (from google-cloud-translate)\n",
      "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-translate)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-translate)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-translate)\n",
      "  Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate) (2.28.1)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate)\n",
      "  Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-translate)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-translate)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-translate)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-translate) (2022.12.7)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-translate)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nagham omar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading google_cloud_translate-3.20.3-py3-none-any.whl (199 kB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-translate\n",
      "\n",
      "   ----------------------------------------  0/14 [pyasn1]\n",
      "   ----------------------------------------  0/14 [pyasn1]\n",
      "   ----------------------------------------  0/14 [pyasn1]\n",
      "   ----------------------------------------  0/14 [pyasn1]\n",
      "   ----------------------------------------  0/14 [pyasn1]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   -- -------------------------------------  1/14 [protobuf]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   ----- ----------------------------------  2/14 [grpcio]\n",
      "   -------- -------------------------------  3/14 [cachetools]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   ----------- ----------------------------  4/14 [rsa]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   -------------- -------------------------  5/14 [pyasn1-modules]\n",
      "   ----------------- ----------------------  6/14 [proto-plus]\n",
      "   ----------------- ----------------------  6/14 [proto-plus]\n",
      "   ----------------- ----------------------  6/14 [proto-plus]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   -------------------- -------------------  7/14 [googleapis-common-protos]\n",
      "   ---------------------- -----------------  8/14 [grpcio-status]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ------------------------- --------------  9/14 [google-auth]\n",
      "   ---------------------------- ----------- 10/14 [grpc-google-iam-v1]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------- -------- 11/14 [google-api-core]\n",
      "   ------------------------------------- -- 13/14 [google-cloud-translate]\n",
      "   ------------------------------------- -- 13/14 [google-cloud-translate]\n",
      "   ------------------------------------- -- 13/14 [google-cloud-translate]\n",
      "   ------------------------------------- -- 13/14 [google-cloud-translate]\n",
      "   ------------------------------------- -- 13/14 [google-cloud-translate]\n",
      "   ---------------------------------------- 14/14 [google-cloud-translate]\n",
      "\n",
      "Successfully installed cachetools-5.5.2 google-api-core-2.25.1 google-auth-2.40.3 google-cloud-core-2.4.3 google-cloud-translate-3.20.3 googleapis-common-protos-1.70.0 grpc-google-iam-v1-0.14.2 grpcio-1.73.0 grpcio-status-1.73.0 proto-plus-1.26.1 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\Nagham Omar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T17:30:19.785389Z",
     "start_time": "2025-06-23T17:30:19.731853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import translate\n",
    "\n",
    "\n",
    "# Path to your JSON key file:\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"positive-bonbon-463817-h1-492e58264930.json\"\n",
    "\n",
    "# Read your CSV file\n",
    "df = pd.read_csv('data/unique_products_with_latest_price_and_promo_FULL.csv')  # <-- Change this to your actual filename\n",
    "\n",
    "# Create the translation client\n",
    "client = translate.Client()\n",
    "\n",
    "def batch_translate(texts, src='he', tgt='en'):\n",
    "    # Google allows up to 128 items per call\n",
    "    results = client.translate(texts, source_language=src, target_language=tgt)\n",
    "    return [r['translatedText'] for r in results]\n",
    "\n",
    "# Batch translation (adjust column name if needed)\n",
    "col_to_translate = 'itemname'  # <-- Change to your column name\n",
    "batch_size = 100\n",
    "translated = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df[col_to_translate].iloc[i:i+batch_size].astype(str).tolist()\n",
    "    translated.extend(batch_translate(batch))\n",
    "    print(f\"{i + len(batch)} / {len(df)} translated...\")\n",
    "\n",
    "df['english_col'] = translated\n",
    "\n",
    "# Save to a new CSV\n",
    "df.to_csv('israeli_supermarkets.csv', index=False)\n",
    "print(\"Done! Translated file saved as israeli_supermarkets.csv\")\n"
   ],
   "id": "fd094ba6eed5006c",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcloud\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m translate\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Path to your JSON key file:\u001B[39;00m\n\u001B[0;32m      7\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGOOGLE_APPLICATION_CREDENTIALS\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositive-bonbon-463817-h1-492e58264930.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T17:29:47.031898Z",
     "start_time": "2025-06-23T17:29:45.298138Z"
    }
   },
   "cell_type": "code",
   "source": "!pip show google-cloud-translate\n",
   "id": "fca338b741e4118e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-cloud-translate\n",
      "Version: 3.20.3\n",
      "Summary: Google Cloud Translate API client library\n",
      "Home-page: https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-translate\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\Nagham Omar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\n",
      "Requires: google-api-core, google-auth, google-cloud-core, grpc-google-iam-v1, proto-plus, protobuf\n",
      "Required-by: \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T17:31:53.846955Z",
     "start_time": "2025-06-23T17:31:53.804761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install google-cloud-translate\n"
   ],
   "id": "33eb7a3813de4e54",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Nagham' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T17:31:54.931905Z",
     "start_time": "2025-06-23T17:31:54.921248Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1c816ac8f127d91f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a38f088e07ed3f57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
